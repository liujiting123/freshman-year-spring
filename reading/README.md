# 说明
读过的文章还是比有笔记的要多一点，但是大多数我都没有像这样做笔记，这是后面才开发出来的习惯。
主要的文章（我记得到我读过的且有点用的）包括：

---

## 🧠 通用深度学习与生成模型

- GAN: Generative Adversarial Nets — Ian Goodfellow et al., 2014  
- WGAN: Wasserstein GAN — Martin Arjovsky et al., 2017  
- Transformer: Attention Is All You Need — Vaswani et al., 2017  
- BERT: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding — Devlin et al., 2018  

---

## 🖼️ 图像生成与理解

- CLIP: Learning Transferable Visual Models From Natural Language Supervision — Alec Radford et al., 2021  
- DINOv2: DINOv2: Learning Robust Visual Features without Supervision — Meta AI, 2023  
- Stable Diffusion: High-Resolution Image Synthesis with Latent Diffusion Models — CompVis, 2022  
- Diffusion Models: Denoising Diffusion Probabilistic Models — Ho et al., 2020  

---

## 🌊 分布学习与表示对齐

- Flow Matching: Flow Matching for Generative Modeling — Lipman et al., 2023  

---

## 🦾 具身智能 Embodied AI

- ACT: Action Chunking with Transformers — Yao et al., 2023  
- SayCan: Do As I Can, Not As I Say: Grounding Language in Robotic Affordances — Google Research, 2022  
- Pi0: Policy Improvement for Language-Conditioned Robotics — Google DeepMind, 2024  
- GR00T: Grounded Robot Reasoning with Optimized and Opened Transformers — NVIDIA, 2024  
- OpenVLA: Generalist Foundation Model for Vision-Language-Action — Alibaba DAMO, 2024  
- One-2-VLA: One Foundation Model for Vision-Language-Action — ZJU & ByteDance, 2024  


因为当时找方向的时候，像人脸识别、红外生成、符号回归也都看过一点，不过忘得差不多了，干脆懒得翻了。还有一些综述文章，记录也删了我也找不到。林林总总的应该还是读了一些
